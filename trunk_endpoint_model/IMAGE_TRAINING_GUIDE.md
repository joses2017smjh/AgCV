# Image-Based Multi-Task Training Guide

## Overview

This training pipeline uses RGB images from scanning (generated by `generate_dataset.py`) to train a CNN model that predicts:
- **Segmentation**: Tree pixel mask
- **Depth**: Per-pixel depth values
- **Radius**: Per-pixel trunk radius
- **Length**: Per-pixel trunk length

## Architecture

- **Encoder**: ResNet-50 (pretrained)
- **Decoder**: U-Net style upsampling
- **Camera Integration**: Camera intrinsics and pose are fused into the model
- **Multi-Task Heads**: Separate heads for segmentation, depth, radius, and length

## Setup

1. **Install dependencies**:
```bash
pip install -r requirements.txt
```

2. **Generate dataset** (if not already done):
```bash
blender36 -b orchard_template.blend -P generate_dataset.py
```

This creates:
- `tree_dataset/rgb/` - RGB images
- `tree_dataset/depth/` - Depth maps (EXR)
- `tree_dataset/ann/` - Camera annotations with intrinsics/pose

## Training

### Basic Training

```bash
python3 trunk_endpoint_model/train_image.py \
    --dataset_dir /home/joses/Ag_Cv/tree_dataset \
    --metadata_dir /home/joses/Ag_Cv/trees/metadata \
    --batch_size 8 \
    --epochs 100 \
    --lr 0.0001 \
    --use_camera \
    --wandb_project tree-image-multitask \
    --wandb_name resnet-unet-baseline
```

### With Custom Loss Weights

```bash
python3 trunk_endpoint_model/train_image.py \
    --dataset_dir /home/joses/Ag_Cv/tree_dataset \
    --metadata_dir /home/joses/Ag_Cv/trees/metadata \
    --batch_size 8 \
    --epochs 100 \
    --seg_weight 1.0 \
    --depth_weight 1.0 \
    --radius_weight 0.5 \
    --length_weight 0.5 \
    --dice_weight 0.5
```

## Metrics Tracked

### Loss Metrics (per batch and epoch)
- `train/batch/loss` - Total training loss
- `train/batch/segmentation_loss` - Segmentation loss (CE + Dice)
- `train/batch/depth_loss` - Depth regression loss (masked Huber)
- `train/batch/radius_loss` - Radius regression loss (masked Huber)
- `train/batch/length_loss` - Length regression loss (masked Huber)
- Same for `val/batch/*` and `val/epoch/*`, `train/epoch/*`

### Accuracy Metrics (per batch and epoch)
- `train/batch/segmentation_accuracy` - Pixel-wise segmentation accuracy
- `train/batch/segmentation_iou` - Intersection over Union for tree pixels
- `train/batch/depth_mae` - Mean Absolute Error for depth (on tree pixels)
- `train/batch/radius_mae` - Mean Absolute Error for radius (on tree pixels)
- `train/batch/length_mae` - Mean Absolute Error for length (on tree pixels)
- Same for `val/batch/*` and `val/epoch/*`, `train/epoch/*`

## Camera Integration

The model uses camera parameters from `generate_dataset.py`:
- **Camera location**: 3D position `[x, y, z]`
- **Camera rotation**: Euler angles `[rx, ry, rz]`
- **Camera intrinsics**: Focal length and principal point from K matrix

These are fused into the model through a learned feature transformation.

## Ground Truth Generation

Ground truth maps are created by:
1. Loading trunk cylinders from metadata JSON
2. Projecting cylinder endpoints to image space using camera parameters
3. Drawing cylinder segments in the image
4. Assigning depth, radius, and length values to tree pixels

## Output

- **Checkpoints**: Saved to `--output_dir` (default: `./checkpoints_image/`)
- **Best model**: `best_model.pth` (lowest validation loss)
- **Wandb logs**: All metrics logged to wandb dashboard

## Viewing Results

1. **Wandb Dashboard**: Visit https://wandb.ai to see:
   - Loss curves (batch and epoch level)
   - Accuracy metrics (batch and epoch level)
   - Learning rate schedule
   - Model checkpoints

2. **Console Output**: Real-time progress with:
   - Batch-level metrics (every 10 batches for train, every 5 for val)
   - Epoch-level summary with all metrics

## Tips

1. **Batch size**: Start with 8, increase if you have GPU memory
2. **Learning rate**: 0.0001 is a good starting point for fine-tuning ResNet
3. **Loss weights**: Adjust based on which tasks are more important
4. **Camera params**: Use `--use_camera` to enable camera feature fusion
5. **Image size**: Default (480, 640) matches generate_dataset.py output

## Troubleshooting

- **Out of memory**: Reduce batch size or image size
- **No samples found**: Check that `dataset_dir` contains `rgb/`, `ann/` subdirectories
- **Poor segmentation**: Increase `seg_weight` or `dice_weight`
- **Depth not learning**: Check that ground truth depth maps are being created correctly


